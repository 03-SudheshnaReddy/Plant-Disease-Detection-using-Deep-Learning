{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":150545,"sourceType":"datasetVersion","datasetId":70909,"isSourceIdPinned":false}],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport cv2\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport time\nimport json\nimport warnings\nimport traceback\nimport kagglehub\n\n# --- Library Imports ---\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.preprocessing import RobustScaler\nfrom skimage.filters import gabor\n\nwarnings.filterwarnings('ignore')\n\n# Directory to save models and results\nOUTPUT_DIR = \"plant_disease_results_ML\"\nos.makedirs(OUTPUT_DIR, exist_ok=True)\n\nclass PlantDiseaseML:\n    def __init__(self, base_path, img_size=(380, 380)):\n        self.base_path = base_path\n        self.img_size = img_size\n        self.class_names = []\n        self.label_map = {}\n        self.results = {}\n\n    def load_images(self):\n        images, labels = [], []\n        if not os.path.exists(self.base_path):\n            raise FileNotFoundError(f\"Dataset path '{self.base_path}' not found!\")\n            \n        self.class_names = sorted([d for d in os.listdir(self.base_path) if os.path.isdir(os.path.join(self.base_path, d))])\n        self.label_map = {name: idx for idx, name in enumerate(self.class_names)}\n        \n        print(f\"Found {len(self.class_names)} classes.\")\n        for class_name in self.class_names:\n            class_path = os.path.join(self.base_path, class_name)\n            for filename in os.listdir(class_path):\n                if filename.lower().endswith(('.jpg', '.jpeg', '.png')):\n                    img_path = os.path.join(class_path, filename)\n                    try:\n                        img = cv2.imread(img_path)\n                        if img is not None:\n                            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n                            img = cv2.resize(img, self.img_size)\n                            images.append(img)\n                            labels.append(self.label_map[class_name])\n                    except Exception as e:\n                        print(f\"Error loading {img_path}: {e}\")\n                        \n        print(f\"Loaded {len(images)} images.\")\n        return np.array(images), np.array(labels)\n\n    def visualize_loaded_images(self, images, labels):\n        print(\"Visualizing a sample of loaded images...\")\n        plt.figure(figsize=(15, 10))\n        random_indices = np.random.choice(len(images), 15, replace=False)\n        for i, idx in enumerate(random_indices):\n            plt.subplot(3, 5, i + 1)\n            plt.imshow(images[idx])\n            plt.title(self.class_names[labels[idx]], fontsize=10)\n            plt.axis('off')\n        plt.tight_layout()\n        save_path = os.path.join(OUTPUT_DIR, 'sample_loaded_images.png')\n        plt.savefig(save_path, dpi=100)\n        plt.close()\n        print(f\"‚úÖ Sample image plot saved to {save_path}\")\n\n    def extract_features_for_ml(self, image):\n        gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n        hsv = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n        features = []\n        for freq in [0.1, 0.5]:\n            for theta in [0, np.pi/4, np.pi/2, 3*np.pi/4]:\n                real, _ = gabor(gray, frequency=freq, theta=theta)\n                features.extend([np.mean(real), np.std(real)])\n        for ch in range(3):\n            features.extend([np.mean(image[:,:,ch]), np.std(image[:,:,ch])])\n            features.extend([np.mean(hsv[:,:,ch]), np.std(hsv[:,:,ch])])\n        return np.nan_to_num(features)\n\n    def generate_evaluation_report(self, y_true, y_pred, model_name):\n        report = classification_report(y_true, y_pred, target_names=self.class_names)\n        report_path = os.path.join(OUTPUT_DIR, f'{model_name}_classification_report.txt')\n        with open(report_path, 'w') as f: f.write(report)\n        print(f\"‚úÖ Classification report saved to {report_path}\")\n\n        cm = confusion_matrix(y_true, y_pred)\n        plt.figure(figsize=(24, 20))\n        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=self.class_names, yticklabels=self.class_names, annot_kws={\"size\": 8})\n        plt.title(f'Confusion Matrix: {model_name}', fontsize=20)\n        plt.ylabel('True Label', fontsize=15)\n        plt.xlabel('Predicted Label', fontsize=15)\n        plt.tight_layout()\n        cm_path = os.path.join(OUTPUT_DIR, f'{model_name}_confusion_matrix.png')\n        plt.savefig(cm_path, dpi=600)\n        plt.close()\n        print(f\"‚úÖ Confusion matrix saved to {cm_path}\")\n\n    def run_ml_analysis(self):\n        print(\"\\n\" + \"=\"*80 + \"\\nüöÄ STARTING MACHINE LEARNING PIPELINE\\n\" + \"=\"*80)\n        \n        print(\"\\n[STEP 1/2] Loading Images and Extracting Features...\")\n        images, labels = self.load_images()\n        if len(images) == 0: return\n        self.visualize_loaded_images(images, labels)\n        \n        features = np.array([self.extract_features_for_ml(img) for img in images])\n        del images # Clear images from memory\n\n        print(\"\\n[STEP 2/2] Training and Evaluating 5 ML Models...\")\n        X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42, stratify=labels)\n        scaler = RobustScaler()\n        X_train_scaled = scaler.fit_transform(X_train)\n        X_test_scaled = scaler.transform(X_test)\n        \n        models = {\n            'RandomForest': RandomForestClassifier(n_estimators=200, random_state=42, n_jobs=-1),\n            'GradientBoosting': GradientBoostingClassifier(n_estimators=200, random_state=42),\n            'SVM': SVC(C=10, kernel='rbf', random_state=42),\n            'KNeighbors': KNeighborsClassifier(n_neighbors=5),\n            'GaussianNB': GaussianNB()\n        }\n        \n        for name, model in models.items():\n            print(f\"\\n--- Training {name} ---\")\n            model.fit(X_train_scaled, y_train)\n            pred = model.predict(X_test_scaled)\n            acc = accuracy_score(y_test, pred)\n            print(f\"{name} Accuracy: {acc:.4f}\")\n            self.generate_evaluation_report(y_test, pred, name)\n            self.results[name] = acc\n        \n        print(\"\\n\" + \"=\"*80 + \"\\nüèÜ FINAL ML MODEL ACCURACY\\n\" + \"=\"*80)\n        df = pd.DataFrame(list(self.results.items()), columns=['Model', 'Accuracy'])\n        print(df.to_string(index=False))\n\nif __name__ == \"__main__\":\n    try:\n        print(\"Downloading dataset from Kaggle Hub...\")\n        download_root_path = kagglehub.dataset_download(\"emmarex/plantdisease\")\n        dataset_path = os.path.join(download_root_path, 'PlantVillage')\n\n        classifier = PlantDiseaseML(base_path=dataset_path)\n        classifier.run_ml_analysis()\n    except Exception as e:\n        print(f\"‚ùå AN UNEXPECTED ERROR OCCURRED: {e}\")\n        traceback.print_exc()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null}]}